{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4VDd8l_8tEtl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QoX2Fg_tkod",
        "outputId": "de6679e0-f2e2-4d65-a2f7-e481366e6963"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ta0E6p0HuOQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "sK13q4AQtw0M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url ='https://www.kaggle.com/datasets/sadmansakibmahi/plant-disease-expert'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "id": "F9UsP_IqtksC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857ae459-0b47-4baf-f5c7-a0e37edbe61e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: intealam\n",
            "Your Kaggle Key: ··········\n",
            "Downloading plant-disease-expert.zip to ./plant-disease-expert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.58G/1.58G [00:09<00:00, 172MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory=r'/content/plant-disease-expert/Image Data base/Image Data base'\n",
        "min_samples=20 # set limit for minimum images a class must have to be included in the dataframe\n",
        "\n",
        "image_paths = [] #list to store image paths     \n",
        "labels=[] #list to store label\n",
        "\n",
        "#storing all classes\n",
        "classlist=os.listdir(directory)   \n",
        "\n",
        "#checking by each label/class\n",
        "for label in classlist:\n",
        "    classpath=os.path.join(directory, label)#path for each label\n",
        "    flist=os.listdir(classpath)#list of all image paths under a label\n",
        "    \n",
        "    #if number of images satisfy the min sample we add it to our lists that will be inturn added to the df\n",
        "    if len(flist) >= min_samples:\n",
        "        for f in flist:\n",
        "            fpath=os.path.join(classpath,f)\n",
        "            image_paths.append(fpath)\n",
        "            labels.append(label)\n",
        "    else:\n",
        "        print(f'Since class {label}  has only {len(flist)} images we will omit it')\n",
        "\n",
        "\n",
        "Impath=pd.Series(image_paths, name='image_paths')\n",
        "lab=pd.Series(labels, name='labels')        \n",
        "\n",
        "\n",
        "df=pd.concat([Impath, lab], axis=1)#Our initial df with image paths \n",
        "\n",
        "\n",
        "train_df, dummy_df=train_test_split(df, train_size=.8, shuffle=True, random_state=42, stratify=df['labels'])\n",
        "valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=42, stratify=dummy_df['labels'])\n",
        "print(f'\\ntrain_df has: {len(train_df)} images,  test_df has:  {len(test_df)} images, valid_df has: {len(valid_df)} images')\n",
        "# get the number of classes and the images count for each class in train_df\n",
        "\n",
        "\n",
        "#check number of images in each class \n",
        "classes=sorted(list(train_df['labels'].unique()))\n",
        "class_count = len(classes)#number of classes\n",
        "print(f'\\nOur initial df has: {class_count} classes')\n",
        "groups=train_df.groupby('labels') #store images by labels\n",
        "\n",
        "\n",
        "#Now let us have a look how many images each class has\n",
        "countlist=[]\n",
        "classlist=[]\n",
        "\n",
        "print('\\n')\n",
        "for label in sorted(list(train_df['labels'].unique())):\n",
        "    group=groups.get_group(label)\n",
        "    countlist.append(len(group))\n",
        "    classlist.append(label)\n",
        "    print(f'{label} has : {len(group)} images')\n",
        "\n",
        "\n",
        "\n",
        "# To check the highest and lowest number of images\n",
        "max_value=np.max(countlist)\n",
        "max_index=countlist.index(max_value)\n",
        "max_class=classlist[max_index]\n",
        "min_value=np.min(countlist)\n",
        "min_index=countlist.index(min_value)\n",
        "min_class=classlist[min_index]\n",
        "print(f'\\n{max_class} has the highest amount of  images with {max_value} images and  {min_class} has the lowest amount of  images with  {min_value} images')"
      ],
      "metadata": {
        "id": "jQlAs20wnMiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22035e66-8bd9-4534-fbec-f037aac6bb9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Since class potassium deficiency in plant  has only 18 images we will omit it\n",
            "Since class Waterlogging in plant  has only 7 images we will omit it\n",
            "Since class tomato canker  has only 19 images we will omit it\n",
            "Since class Nitrogen deficiency in plant  has only 11 images we will omit it\n",
            "\n",
            "train_df has: 53200 images,  test_df has:  6651 images, valid_df has: 6650 images\n",
            "\n",
            "Our initial df has: 54 classes\n",
            "\n",
            "\n",
            "Apple Apple scab has : 1613 images\n",
            "Apple Black rot has : 1590 images\n",
            "Apple Cedar apple rust has : 704 images\n",
            "Apple healthy has : 1053 images\n",
            "Bacterial leaf blight in rice leaf has : 32 images\n",
            "Blight in corn Leaf has : 917 images\n",
            "Blueberry healthy has : 962 images\n",
            "Brown spot in rice leaf has : 32 images\n",
            "Cercospora leaf spot has : 51 images\n",
            "Cherry (including sour) Powdery mildew has : 674 images\n",
            "Cherry (including_sour) healthy has : 547 images\n",
            "Common Rust in corn Leaf has : 1045 images\n",
            "Corn (maize) healthy has : 744 images\n",
            "Garlic has : 39 images\n",
            "Grape Black rot has : 3021 images\n",
            "Grape Esca Black Measles has : 3542 images\n",
            "Grape Leaf blight Isariopsis Leaf Spot has : 2755 images\n",
            "Grape healthy has : 271 images\n",
            "Gray Leaf Spot in corn Leaf has : 459 images\n",
            "Leaf smut in rice leaf has : 32 images\n",
            "Orange Haunglongbing Citrus greening has : 14099 images\n",
            "Peach healthy has : 230 images\n",
            "Pepper bell Bacterial spot has : 798 images\n",
            "Pepper bell healthy has : 946 images\n",
            "Potato Early blight has : 800 images\n",
            "Potato Late blight has : 800 images\n",
            "Potato healthy has : 98 images\n",
            "Raspberry healthy has : 238 images\n",
            "Sogatella rice has : 21 images\n",
            "Soybean healthy has : 3258 images\n",
            "Strawberry Leaf scorch has : 710 images\n",
            "Strawberry healthy has : 292 images\n",
            "Tomato Bacterial spot has : 1702 images\n",
            "Tomato Early blight has : 800 images\n",
            "Tomato Late blight has : 1527 images\n",
            "Tomato Leaf Mold has : 762 images\n",
            "Tomato Septoria leaf spot has : 1417 images\n",
            "Tomato Spider mites Two spotted spider mite has : 1341 images\n",
            "Tomato Target Spot has : 1123 images\n",
            "Tomato Tomato mosaic virus has : 298 images\n",
            "Tomato healthy has : 1018 images\n",
            "algal leaf in tea has : 90 images\n",
            "anthracnose in tea has : 80 images\n",
            "bird eye spot in tea has : 80 images\n",
            "brown blight in tea has : 90 images\n",
            "cabbage looper has : 62 images\n",
            "corn crop has : 83 images\n",
            "ginger has : 36 images\n",
            "healthy tea leaf has : 59 images\n",
            "lemon canker has : 49 images\n",
            "onion has : 16 images\n",
            "potato crop has : 32 images\n",
            "potato hollow heart has : 48 images\n",
            "red leaf spot in tea has : 114 images\n",
            "\n",
            "Orange Haunglongbing Citrus greening has the highest amount of  images with 14099 images and  onion has the lowest amount of  images with  16 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(df, max_images, min_images):\n",
        "\n",
        "  \"\"\"\n",
        "  This function will input a df and return a trimmed df with only x amount of max images per class\n",
        "\n",
        "  \"\"\"\n",
        "  trimmed_df = pd.DataFrame(columns = df.columns)#df where we stored our trimmed image paths\n",
        "  \n",
        "  groups=df.groupby('labels')#store images by group\n",
        "  \n",
        "  \n",
        "  for label in df['labels'].unique(): \n",
        "        group=groups.get_group(label)#store images in a class\n",
        "        \n",
        "        number_of_images=len(group) #number of images in a class\n",
        "        #if images > max images then we randomly pick 'max images'   \n",
        "        if number_of_images > max_images:\n",
        "            s=group.sample(n=max_images, random_state=42,axis=0) #we pick x amount of random samples\n",
        "            trimmed_df=pd.concat([trimmed_df, s], axis=0)#add to df\n",
        "        else:\n",
        "            #Now if number of images is > min images but < max images, we simply add it to the df and fill later with augmented images\n",
        "            if number_of_images >=min_images:\n",
        "                s=group        \n",
        "                trimmed_df=pd.concat([trimmed_df, s], axis=0)#add to df\n",
        "  \n",
        "  \n",
        "  print(f'The max images are:{max_images} and the minimum images are: {min_images}')\n",
        "  return trimmed_df"
      ],
      "metadata": {
        "id": "mZUgz2G6bUsq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_images=500 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
        "min_images=16\n",
        "column='labels'\n",
        "train_df= trim(train_df, max_images, min_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz-WfYKlp76O",
        "outputId": "4c47056e-fd47-4215-f681-79141a2cccad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max images are:500 and the minimum images are: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Augment(df, n, working_dir, img_size):\n",
        "\n",
        "\n",
        "    print('Initial length of dataframe is ', len(df))\n",
        "    \n",
        "    \n",
        "    augment_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
        "    \n",
        "    \n",
        "    if os.path.isdir(augment_dir):# start with an empty directory\n",
        "        shutil.rmtree(augment_dir)\n",
        "    os.mkdir(augment_dir)        \n",
        "    \n",
        "    \n",
        "    for label in df['labels'].unique():    \n",
        "        dir_path=os.path.join(augment_dir,label)    \n",
        "        os.mkdir(dir_path) # make class directories within aug directory\n",
        "    \n",
        "    \n",
        "    #counter variable for total augmented images\n",
        "    total=0\n",
        "    Aug_gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
        "                                  height_shift_range=.2, zoom_range=.2)\n",
        "    \n",
        "    \n",
        "    groups=df.groupby('labels') # store images grouped by class\n",
        "    \n",
        "    \n",
        "    for label in df['labels'].unique():            \n",
        "        group=groups.get_group(label)  # store image paths for a particular label\n",
        "        number_of_images=len(group)   # determine how many samples there are in this class        \n",
        "        if number_of_images< n: # if the class has less than target number of images\n",
        "            aug_img_count=0 # counter variable for number of aug images created for that class\n",
        "            difference=n - number_of_images  # number of augmented images to create\n",
        "            target_dir=os.path.join(augment_dir, label)  # define where to write the images\n",
        "            print(f'For {label} creating {difference} augmented images. ',end='')\n",
        "            #print(msg, '\\r', end='') # prints over on the same line\n",
        "            aug_gen=Aug_gen.flow_from_dataframe( group,  x_col='image_paths', y_col=None, target_size=img_size,\n",
        "                                            class_mode=None, batch_size=1, shuffle=False, \n",
        "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
        "                                            save_format='jpg')\n",
        "            while aug_img_count<difference:\n",
        "                images=next(aug_gen)            \n",
        "                aug_img_count += len(images)\n",
        "            total +=aug_img_count\n",
        "    print('Total Augmented images created= ', total)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Now create an augmented df and merge it with the initial df \n",
        "    \n",
        "    \n",
        "    \n",
        "    aug_image_paths=[]\n",
        "    aug_labels=[]\n",
        "    classlist=os.listdir(augment_dir)\n",
        "    for label in classlist:\n",
        "        classpath=os.path.join(augment_dir, label)     \n",
        "        flist=os.listdir(classpath)    \n",
        "        for f in flist:        \n",
        "            fpath=os.path.join(classpath,f)         \n",
        "            aug_image_paths.append(fpath)\n",
        "            aug_labels.append(label)\n",
        "    impath=pd.Series(aug_image_paths, name='image_paths')\n",
        "    lab=pd.Series(aug_labels, name='labels')\n",
        "    augment_df=pd.concat([impath, lab], axis=1)         \n",
        "    df=pd.concat([df,augment_df], axis=0).reset_index(drop=True)\n",
        "    print('Length of augmented dataframe :', len(df))\n",
        "    return df"
      ],
      "metadata": {
        "id": "aPBlyYDcbXEf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=500 # number of samples in each class\n",
        "working_dir=r'./' # directory to store augmented images\n",
        "img_size=(224,224) # size of augmented images\n",
        "train_df=Augment(train_df, n, working_dir, img_size)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nowGZJEHsdLM",
        "outputId": "96f8cd70-d818-4b33-9417-0425d9a36359"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial length of dataframe is  16932\n",
            "For anthracnose in tea creating 420 augmented images. Found 80 validated image filenames.\n",
            "For Grape healthy creating 229 augmented images. Found 271 validated image filenames.\n",
            "For potato hollow heart creating 452 augmented images. Found 48 validated image filenames.\n",
            "For Tomato Tomato mosaic virus creating 202 augmented images. Found 298 validated image filenames.\n",
            "For lemon canker creating 451 augmented images. Found 49 validated image filenames.\n",
            "For Raspberry healthy creating 262 augmented images. Found 238 validated image filenames.\n",
            "For red leaf spot in tea creating 386 augmented images. Found 114 validated image filenames.\n",
            "For Strawberry healthy creating 208 augmented images. Found 292 validated image filenames.\n",
            "For corn crop creating 417 augmented images. Found 83 validated image filenames.\n",
            "For Gray Leaf Spot in corn Leaf creating 41 augmented images. Found 459 validated image filenames.\n",
            "For Potato healthy creating 402 augmented images. Found 98 validated image filenames.\n",
            "For Peach healthy creating 270 augmented images. Found 230 validated image filenames.\n",
            "For Cercospora leaf spot creating 449 augmented images. Found 51 validated image filenames.\n",
            "For cabbage looper creating 438 augmented images. Found 62 validated image filenames.\n",
            "For brown blight in tea creating 410 augmented images. Found 90 validated image filenames.\n",
            "For Garlic creating 461 augmented images. Found 39 validated image filenames.\n",
            "For Bacterial leaf blight in rice leaf creating 468 augmented images. Found 32 validated image filenames.\n",
            "For bird eye spot in tea creating 420 augmented images. Found 80 validated image filenames.\n",
            "For healthy tea leaf creating 441 augmented images. Found 59 validated image filenames.\n",
            "For potato crop creating 468 augmented images. Found 32 validated image filenames.\n",
            "For algal leaf in tea creating 410 augmented images. Found 90 validated image filenames.\n",
            "For onion creating 484 augmented images. Found 16 validated image filenames.\n",
            "For Sogatella rice creating 479 augmented images. Found 21 validated image filenames.\n",
            "For Brown spot in rice leaf creating 468 augmented images. Found 32 validated image filenames.\n",
            "For Leaf smut in rice leaf creating 468 augmented images. Found 32 validated image filenames.\n",
            "For ginger creating 464 augmented images. Found 36 validated image filenames.\n",
            "Total Augmented images created=  10068\n",
            "Length of augmented dataframe : 27000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32 \n",
        "\n",
        "\n",
        "traingen0=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n",
        "                                  height_shift_range=.2, zoom_range=.2 )\n",
        "\n",
        "\n",
        "test_and_val_gen=ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_gen=traingen0.flow_from_dataframe(train_df, x_col='image_paths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "valid_gen=test_and_val_gen.flow_from_dataframe(valid_df, x_col='image_paths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
        "# this insures that we go through all the sample in the test set exactly once.\n",
        "\n",
        "length=len(test_df)\n",
        "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
        "test_steps=int(length/test_batch_size)\n",
        "\n",
        "\n",
        "\n",
        "test_gen=test_and_val_gen.flow_from_dataframe(test_df, x_col='image_paths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# from the generator we can get information we will need later\n",
        "classes=list(train_gen.class_indices.keys())\n",
        "class_indices=list(train_gen.class_indices.values())\n",
        "class_count=len(classes)\n",
        "labels=test_gen.labels\n",
        "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQR62FwObZzR",
        "outputId": "fafca075-dd70-403c-e756-f8876608f4e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27000 validated image filenames belonging to 54 classes.\n",
            "Found 6650 validated image filenames belonging to 54 classes.\n",
            "Found 6651 validated image filenames belonging to 54 classes.\n",
            "test batch size:  9   test steps:  739  number of classes :  54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_shape=(img_size[0], img_size[1], 3)\n",
        "\n",
        "model_name='EfficientNetB3'\n",
        "\n",
        "\n",
        "base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
        "\n",
        "base_model.trainable=True\n",
        "\n",
        "x=base_model.output\n",
        "\n",
        "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "\n",
        "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
        "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
        "\n",
        "x=Dropout(rate=.4, seed=42)(x)       \n",
        "\n",
        "output=Dense(class_count, activation='softmax')(x)\n",
        "\n",
        "model=Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "lr=.001 # start with this learning rate\n",
        "model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA8YyS9UbeTs",
        "outputId": "63313aaa-7107-45a2-be7e-2d1ddf5ea453"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941136/43941136 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LR_ASK(keras.callbacks.Callback):\n",
        "    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n",
        "        super(LR_ASK, self).__init__()\n",
        "        self.model=model               \n",
        "        self.ask_epoch=ask_epoch\n",
        "        self.epochs=epochs\n",
        "        self.ask=True # if True query the user on a specified epoch\n",
        "        self.lowest_vloss=np.inf\n",
        "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
        "        self.best_epoch=1\n",
        "        \n",
        "        \n",
        "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
        "        if self.ask_epoch == 0: \n",
        "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
        "            self.ask_epoch=1\n",
        "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
        "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
        "            self.ask=False # do not query the user\n",
        "        if self.epochs == 1:\n",
        "            self.ask=False # running only for 1 epoch so do not query user\n",
        "        else:\n",
        "            print('Training will proceed until epoch:', ask_epoch,' then you will be asked to') \n",
        "            print(' enter H or 0 to halt training or enter a positive integer for how many more epochs to run the model before being asked again')  \n",
        "        self.start_time= time.time() # set the time at which training started\n",
        "        \n",
        "    def on_train_end(self, logs=None):   # runs at the end of training  \n",
        "        print('loading model with weights from epoch ', self.best_epoch)\n",
        "        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
        "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n",
        "        hours = tr_duration // 3600\n",
        "        minutes = (tr_duration - (hours * 3600)) // 60\n",
        "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
        "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
        "        print (msg, flush=True) # print out training duration time\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
        "        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n",
        "        if v_loss< self.lowest_vloss:\n",
        "            self.lowest_vloss=v_loss\n",
        "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
        "            self.best_epoch=epoch + 1\n",
        "            print (f'\\n validation loss of {v_loss:7.4f} is below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights')\n",
        "        else:\n",
        "            print (f'\\n validation loss of {v_loss:7.4f} is above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights')\n",
        "        \n",
        "        if self.ask: # are the conditions right to query the user?\n",
        "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
        "                print('\\n Enter H or 0 to end training or  a positive  integer for the number of additional epochs to run the model before being asked again')\n",
        "                ans=input()\n",
        "                \n",
        "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
        "                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n",
        "                    self.model.stop_training = True # halt training\n",
        "                else: # user wants to continue training\n",
        "                    self.ask_epoch += int(ans)\n",
        "                    if self.ask_epoch > self.epochs:\n",
        "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
        "                    else:\n",
        "                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)\n",
        "                        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
        "                        print(f'current LR is  {lr:7.5f}  hit enter to keep  this LR or enter a new LR')\n",
        "                        ans=input(' ')\n",
        "                        if ans =='':\n",
        "                            print (f'keeping current LR of {lr:7.5f}')\n",
        "                        else:\n",
        "                            new_lr=float(ans)\n",
        "                            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
        "                            print(' changing LR to ', ans)"
      ],
      "metadata": {
        "id": "xlTbedi5bj56"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "ask_epoch=5\n",
        "ask=LR_ASK(model, epochs,  ask_epoch)\n",
        "#rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n",
        "#callbacks=[rlronp, ask]\n",
        "callbacks=[ask]"
      ],
      "metadata": {
        "id": "XWdS__NMbm2f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n",
        "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaOQrb_ncnFM",
        "outputId": "6f49bf3a-32f0-4c52-825a-884927c68734"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training will proceed until epoch: 5  then you will be asked to\n",
            " enter H or 0 to halt training or enter a positive integer for how many more epochs to run the model before being asked again\n",
            "Epoch 1/20\n",
            "  6/844 [..............................] - ETA: 8:59 - loss: 12.1478 - accuracy: 0.0885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3098s vs `on_train_batch_end` time: 0.3282s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "844/844 [==============================] - ETA: 0s - loss: 4.3973 - accuracy: 0.8348\n",
            " validation loss of  1.4002 is below lowest loss, saving weights from epoch 1   as best weights\n",
            "844/844 [==============================] - 569s 674ms/step - loss: 4.3973 - accuracy: 0.8348 - val_loss: 1.4002 - val_accuracy: 0.9774\n",
            "Epoch 2/20\n",
            "844/844 [==============================] - ETA: 0s - loss: 0.9376 - accuracy: 0.9669\n",
            " validation loss of  0.5921 is below lowest loss, saving weights from epoch 2   as best weights\n",
            "844/844 [==============================] - 563s 666ms/step - loss: 0.9376 - accuracy: 0.9669 - val_loss: 0.5921 - val_accuracy: 0.9765\n",
            "Epoch 3/20\n",
            "844/844 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.9759\n",
            " validation loss of  0.4602 is below lowest loss, saving weights from epoch 3   as best weights\n",
            "844/844 [==============================] - 564s 668ms/step - loss: 0.5836 - accuracy: 0.9759 - val_loss: 0.4602 - val_accuracy: 0.9841\n",
            "Epoch 4/20\n",
            "844/844 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.9831\n",
            " validation loss of  0.4457 is below lowest loss, saving weights from epoch 4   as best weights\n",
            "844/844 [==============================] - 567s 672ms/step - loss: 0.4728 - accuracy: 0.9831 - val_loss: 0.4457 - val_accuracy: 0.9716\n",
            "Epoch 5/20\n",
            "844/844 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.9876\n",
            " validation loss of  0.3437 is below lowest loss, saving weights from epoch 5   as best weights\n",
            "\n",
            " Enter H or 0 to end training or  a positive  integer for the number of additional epochs to run the model before being asked again\n",
            "h\n",
            "you entered  h  Training halted on epoch  5  due to user input\n",
            "\n",
            "844/844 [==============================] - 571s 677ms/step - loss: 0.4011 - accuracy: 0.9876 - val_loss: 0.3437 - val_accuracy: 0.9875\n",
            "loading model with weights from epoch  5\n",
            "training elapsed time was 0.0 hours, 48.0 minutes, 12.50 seconds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tr_plot(tr_data, start_epoch):\n",
        "    #Plot the training and validation data\n",
        "    \n",
        "    \n",
        "    tacc=tr_data.history['accuracy']\n",
        "    tloss=tr_data.history['loss']\n",
        "    vacc=tr_data.history['val_accuracy']\n",
        "    vloss=tr_data.history['val_loss']\n",
        "    Epoch_count=len(tacc)+ start_epoch\n",
        "    Epochs=[]\n",
        "    for i in range (start_epoch ,Epoch_count):\n",
        "        Epochs.append(i+1)   \n",
        "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
        "    val_lowest=vloss[index_loss]\n",
        "    index_acc=np.argmax(vacc)\n",
        "    acc_highest=vacc[index_acc]\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
        "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
        "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
        "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
        "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
        "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
        "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
        "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "    plt.tight_layout    \n",
        "    plt.show()\n",
        "    \n",
        "tr_plot(m1,0)"
      ],
      "metadata": {
        "id": "6hlV0wi_crts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model,load_model\n"
      ],
      "metadata": {
        "id": "H6m1wIyn6STC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model,'/content/drive/MyDrive/Data/models/plantdisease500.h5')"
      ],
      "metadata": {
        "id": "XQqO2Xc26zLL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(model,test_gen, test_steps):\n",
        "    y_pred= []\n",
        "    y_true=test_gen.labels\n",
        "    classes=list(test_gen.class_indices.keys())\n",
        "    class_count=len(classes)\n",
        "    errors=0\n",
        "    preds=model.predict(test_gen, verbose=1)\n",
        "    tests=len(preds)    \n",
        "    for i, p in enumerate(preds):        \n",
        "        pred_index=np.argmax(p)         \n",
        "        true_index=test_gen.labels[i]  # labels are integer values        \n",
        "        if pred_index != true_index: # a misclassification has occurred                                           \n",
        "            errors=errors + 1\n",
        "        y_pred.append(pred_index)\n",
        "            \n",
        "    acc=( 1-errors/tests) * 100 \n",
        "    print(f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}')\n",
        "    ypred=np.array(y_pred)\n",
        "    ytrue=np.array(y_true)\n",
        "    if class_count <=30:\n",
        "        cm = confusion_matrix(ytrue, ypred )\n",
        "        # plot the confusion matrix\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n",
        "        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "    return errors, tests\n",
        "errors, tests=predictor(m1,test_gen, test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5g-CLMt7IZa",
        "outputId": "20b5f30f-fca1-4352-8b37-51c454965413"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "739/739 [==============================] - 962s 1s/step\n",
            "there were 51 errors in 6651 tests for an accuracy of  99.23\n",
            "Classification Report:\n",
            "----------------------\n",
            "                                              precision    recall  f1-score   support\n",
            "\n",
            "                           Apple Apple scab     1.0000    0.9950    0.9975       202\n",
            "                            Apple Black rot     1.0000    1.0000    1.0000       199\n",
            "                     Apple Cedar apple rust     1.0000    1.0000    1.0000        88\n",
            "                              Apple healthy     0.9925    1.0000    0.9962       132\n",
            "         Bacterial leaf blight in rice leaf     1.0000    1.0000    1.0000         4\n",
            "                        Blight in corn Leaf     0.9730    0.9391    0.9558       115\n",
            "                          Blueberry healthy     1.0000    1.0000    1.0000       120\n",
            "                    Brown spot in rice leaf     1.0000    1.0000    1.0000         4\n",
            "                       Cercospora leaf spot     1.0000    1.0000    1.0000         6\n",
            "     Cherry (including sour) Powdery mildew     1.0000    1.0000    1.0000        84\n",
            "            Cherry (including_sour) healthy     1.0000    1.0000    1.0000        68\n",
            "                   Common Rust in corn Leaf     0.9922    0.9771    0.9846       131\n",
            "                       Corn (maize) healthy     1.0000    1.0000    1.0000        93\n",
            "                                     Garlic     1.0000    1.0000    1.0000         5\n",
            "                            Grape Black rot     1.0000    0.9868    0.9933       378\n",
            "                   Grape Esca Black Measles     0.9888    1.0000    0.9944       443\n",
            "     Grape Leaf blight Isariopsis Leaf Spot     1.0000    1.0000    1.0000       345\n",
            "                              Grape healthy     1.0000    1.0000    1.0000        34\n",
            "                Gray Leaf Spot in corn Leaf     0.8594    0.9649    0.9091        57\n",
            "                     Leaf smut in rice leaf     1.0000    1.0000    1.0000         4\n",
            "       Orange Haunglongbing Citrus greening     1.0000    1.0000    1.0000      1763\n",
            "                              Peach healthy     1.0000    1.0000    1.0000        29\n",
            "                 Pepper bell Bacterial spot     1.0000    0.9900    0.9950       100\n",
            "                        Pepper bell healthy     0.9917    1.0000    0.9958       119\n",
            "                        Potato Early blight     1.0000    0.9900    0.9950       100\n",
            "                         Potato Late blight     0.9434    1.0000    0.9709       100\n",
            "                             Potato healthy     1.0000    0.7500    0.8571        12\n",
            "                          Raspberry healthy     1.0000    1.0000    1.0000        29\n",
            "                             Sogatella rice     1.0000    1.0000    1.0000         2\n",
            "                            Soybean healthy     0.9951    1.0000    0.9975       407\n",
            "                     Strawberry Leaf scorch     1.0000    1.0000    1.0000        89\n",
            "                         Strawberry healthy     1.0000    1.0000    1.0000        36\n",
            "                      Tomato Bacterial spot     1.0000    0.9812    0.9905       213\n",
            "                        Tomato Early blight     0.9706    0.9900    0.9802       100\n",
            "                         Tomato Late blight     0.9946    0.9581    0.9760       191\n",
            "                           Tomato Leaf Mold     1.0000    0.9579    0.9785        95\n",
            "                  Tomato Septoria leaf spot     0.9943    0.9831    0.9886       177\n",
            "Tomato Spider mites Two spotted spider mite     0.9655    1.0000    0.9825       168\n",
            "                         Tomato Target Spot     0.9714    0.9645    0.9680       141\n",
            "                 Tomato Tomato mosaic virus     1.0000    1.0000    1.0000        37\n",
            "                             Tomato healthy     0.9621    0.9922    0.9769       128\n",
            "                          algal leaf in tea     1.0000    1.0000    1.0000        11\n",
            "                         anthracnose in tea     0.9091    1.0000    0.9524        10\n",
            "                       bird eye spot in tea     0.9000    0.9000    0.9000        10\n",
            "                        brown blight in tea     1.0000    1.0000    1.0000        11\n",
            "                             cabbage looper     1.0000    0.8750    0.9333         8\n",
            "                                  corn crop     1.0000    1.0000    1.0000        10\n",
            "                                     ginger     1.0000    1.0000    1.0000         4\n",
            "                           healthy tea leaf     1.0000    1.0000    1.0000         7\n",
            "                               lemon canker     1.0000    1.0000    1.0000         6\n",
            "                                      onion     0.6667    1.0000    0.8000         2\n",
            "                                potato crop     1.0000    1.0000    1.0000         4\n",
            "                        potato hollow heart     1.0000    1.0000    1.0000         6\n",
            "                       red leaf spot in tea     1.0000    1.0000    1.0000        14\n",
            "\n",
            "                                   accuracy                         0.9923      6651\n",
            "                                  macro avg     0.9828    0.9851    0.9828      6651\n",
            "                               weighted avg     0.9926    0.9923    0.9924      6651\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "yedfGKuE7w7q",
        "outputId": "c61d6636-3b4b-4029-ad20-067fa3f419b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1=load_model('/content/drive/MyDrive/Data/models/plantdisease500.h5')"
      ],
      "metadata": {
        "id": "A3tvmvUUKfJZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.m1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "YIcZhQVKL8gk",
        "outputId": "b68fdd06-8df8-47a0-b2c2-224f64361fbd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a92d94d3c290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6oEYGowYnxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}